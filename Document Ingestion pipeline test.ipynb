{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f79931-4d5f-4cad-bd1a-ecb44388fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "import boto3, json, os\n",
    "from botocore.config import Config\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "os.environ['AWS_PROFILE'] = \"\"\n",
    "os.environ['AWS_DEFAULT_REGION'] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add9337-d04b-4e3e-89a8-7667b600f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be93a5-abda-4b8d-90f7-9ccad873da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer, StorageContext\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1f01a-f20c-47aa-9190-25b78dc237e5",
   "metadata": {},
   "source": [
    "### Ingesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88974c61-a3cd-4047-8eef-95b8be2e3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ingesting documents from Local\n",
    "\n",
    "\n",
    "data_root = \"./juergen_data/\"\n",
    "\n",
    "filenames = [\"capturing-the-full-value-of-generative-ai-in-banking\",\n",
    "             \"Industry4_BigBets_Oct25\"]\n",
    "#            \"Industry4_Framework_10_03\",\n",
    "#            \"JuergenLindner_Resume_Jan2024\",\n",
    "#            \"State_of_Industry_4.0_Research_Overview_2022\",\n",
    "#            \"technologys-generational-moment-with-generative-ai-a-cio-and-cto-guide\"]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"{data_root}/{filename}.pdf\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\",\"\")\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddb613-a2a4-479d-b24b-90c02b0a6d45",
   "metadata": {},
   "source": [
    "## Run the Redis-Based Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621d366-f4c4-432c-8a49-436e3924c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.redis import RedisVectorStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84446d87-731a-45ee-915c-fc227b6c8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "text_splitter = SentenceSplitter(chunk_size=3000)\n",
    "embed_model = OpenAI(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277188e2-f618-4c2c-98c3-56bbc0257d2c",
   "metadata": {},
   "source": [
    "### Setting up vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e310af-9553-4f9a-931f-f249346f06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_HOST = ''\n",
    "REDIS_PORT = 6379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaafe82-1405-4ce5-897c-6d4247388e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fd123-66a5-461f-afcb-3c4acc4b33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = make_url(\"postgres://postgres.<Username>:<Password>@aws-0-us-west-1.pooler.supabase.com:5432/postgres\")\n",
    "db_name=\"postgres\"\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=url.database,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"test-llamaindex-aiva\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28effa4-7db8-4767-a47b-ba6c22aa20ef",
   "metadata": {},
   "source": [
    "### Create connection to Redis cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826796c3-9999-48b1-abed-569793361c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_host_and_port(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"redis-document-store\"\n",
    "    ),\n",
    "    \n",
    "    index_store=RedisIndexStore.from_host_and_port(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"redis-index-store\"\n",
    "    ),\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66879187-c811-4936-b771-4677c277473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summary_index = DocumentSummaryIndex.from_documents(docs,\n",
    "    llm=llm,\n",
    "    transformations=[text_splitter],\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    "    storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d16ff0-a2ab-40eb-9fe6-51a6be717ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))\n",
    "\n",
    "new_summary_tmpl_str = (\n",
    "    \"Context information is below:\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge,\"\n",
    "    \"answer the query in the style of a McKinsey, Bain or BCG consultant who specializes in digital transformation strategies.\"\n",
    "    \"Your goal is to help business users succeed in their digital transformation journeys.\"\n",
    "    \"Do not use any context outside of these documents.\"\n",
    "    \"If a question is outside of your area of expertise, politely refuse to answer and suggest alternative topics of discussion from the context provided.\"\n",
    "    \"You should maintain a friendly yet professional tone.\"\n",
    "    \"Use detailed bullet points whenever relevant.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "new_summary_tmpl = PromptTemplate(new_summary_tmpl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51d093-5649-4237-b37c-bf2edbfd0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexEmbeddingRetriever,\n",
    ")\n",
    "\n",
    "from llama_index.core import load_indices_from_storage\n",
    "\n",
    "## Uncomment during inference\n",
    "#doc_summary_index = load_indices_from_storage(\n",
    "#    storage_context=storage_context\n",
    "    #index_id=index_id\n",
    "#)\n",
    "\n",
    "# Configuring response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(streaming=True, response_mode=\"tree_summarize\")\n",
    "\n",
    "## Creating Retreiver object\n",
    "retriever = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    doc_summary_index,\n",
    "    choice_batch_size=10,\n",
    "    choice_top_k=5\n",
    ")\n",
    "\n",
    "# Assembling query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "## Checking default query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)\n",
    "\n",
    "## Modifying query prompt\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": new_summary_tmpl}\n",
    ")\n",
    "\n",
    "## Checking modified query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc5c45-a2f5-4e0b-b6e0-726f8702d3f3",
   "metadata": {},
   "source": [
    "### Embeddings Retirever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d6f9a-7d54-492f-a02e-6604ea7e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# query\n",
    "response = query_engine.query(\"Given me a detailed explanation about the likely impact of Industry 4.0 digital transformation strategies?\")\n",
    "response.print_response_stream()\n",
    "\n",
    "## Use streaming response in block:\n",
    "'''for text in streaming_response.response_gen:\n",
    "    # do something with text as they arrive.\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8f57b-d88f-4258-bdba-a6627ea0cc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
