{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94bce1e-fec6-4836-bc66-e570975479ee",
   "metadata": {},
   "source": [
    "### Package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3c056-f665-44b7-b9a6-1a988a0be856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "282648fb-8f35-4dd7-8e8a-f9fec4960ca0",
   "metadata": {},
   "source": [
    "## Document Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dacf00-2959-4f22-9fee-0dfc92fcf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ID of SME for data labeling\n",
    "\n",
    "sme_id = 'sme_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f79931-4d5f-4cad-bd1a-ecb44388fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add9337-d04b-4e3e-89a8-7667b600f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be93a5-abda-4b8d-90f7-9ccad873da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer, StorageContext\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf17a8e-01bb-4083-8053-24310cdc8ed7",
   "metadata": {},
   "source": [
    "#### Parsing files and loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e0bc8-e0ed-456a-9799-cfcb4a1ea7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./ritika_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024091e-b425-45b4-990f-51490caa9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ingesting documents from Local\n",
    "\n",
    "filenames = [\"Decarbonizing-the-Built-World-A-Call-to-Action-2023-03-07\",\n",
    "             \"Digital-Twin-Capabilities-Periodic-Table-User-Guide\",\n",
    "             \"Digital-Twin-System-Interoperability-Framework-12072021\",\n",
    "             \"DTC-Reality-Capture-Industry-User-Guide-for-Tenant-Improvement-Projects-2023-06-07\",\n",
    "             \"Infrastructure-Digital-Twin-Maturity-Model\"]\n",
    "             #\"Platform-Stack-Architectural-Framework\",\n",
    "             #\"Reality-Capture-A-Digital-Twin-Foundation\",\n",
    "             #\"SMM-Digital-Twin-Profile-2022-06-20\",\n",
    "             #\"User-Guide-1-Why-and-What-2023-07-18\",\n",
    "             #\"User-Guide-2-Identifying-and-Aligning\",\n",
    "             #\"User-Guide-3_A-Whole_Systems_Approach\"]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"{data_root}/{filename}.pdf\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\",\"\")\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddb613-a2a4-479d-b24b-90c02b0a6d45",
   "metadata": {},
   "source": [
    "#### Redis-Based Ingestion Pipeline for Doc store and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621d366-f4c4-432c-8a49-436e3924c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.redis import RedisVectorStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84446d87-731a-45ee-915c-fc227b6c8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "text_splitter = SentenceSplitter(chunk_size=3000)\n",
    "embed_model = OpenAI(model=\"text-embedding-3-small\")\n",
    "text_splitter = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277188e2-f618-4c2c-98c3-56bbc0257d2c",
   "metadata": {},
   "source": [
    "#### Setting up document store, index store and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d07905-08da-4079-b0d6-c3502902c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up connection to Redis two ways:\n",
    "\n",
    "## Through Python Redis client:\n",
    "\n",
    "import redis\n",
    "redis_client = redis.Redis(\n",
    "  host='',\n",
    "  port=,\n",
    "  password='')\n",
    "\n",
    "## Through host and port:\n",
    "\n",
    "#REDIS_HOST = os.getenv(\"REDIS_HOST\", \"127.0.0.1\")\n",
    "#REDIS_PORT = os.getenv(\"REDIS_PORT\", 6379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fd123-66a5-461f-afcb-3c4acc4b33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining PGVector database:\n",
    "\n",
    "from sqlalchemy import make_url\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "url = make_url(\"postgres://postgres.<username>:<password>@aws-0-us-west-1.pooler.supabase.com:5432/postgres\")\n",
    "db_name=\"postgres\"\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=url.database,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=sme_id,\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28effa4-7db8-4767-a47b-ba6c22aa20ef",
   "metadata": {},
   "source": [
    "#### Creating storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826796c3-9999-48b1-abed-569793361c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Through Redis client:\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    \n",
    "    index_store=RedisIndexStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f4325-3b67-4eb6-8666-4870fffd7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Through Redis host and port:\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_redis_client(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"llama_index\"\n",
    "    ),\n",
    "    \n",
    "    index_store=RedisIndexStore.from_redis_client(\n",
    "        host=REDIS_HOST, port=REDIS_PORT, namespace=\"llama_index\"\n",
    "    ),\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac557b-9f4a-4e4c-80b3-713ca6d56afa",
   "metadata": {},
   "source": [
    "#### Creating Document Summary Index and storing in respective db locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66879187-c811-4936-b771-4677c277473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summary_index = DocumentSummaryIndex.from_documents(docs,\n",
    "    llm=llm,\n",
    "    transformations=[text_splitter],\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    "    storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d755e1-814c-4f1b-99c3-633e336ce81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fin ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea697738-5148-415e-a26f-fe7ae8b6d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restart kernel to test Pipeline below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8470c09-5771-45ab-91ab-5514292dc30d",
   "metadata": {},
   "source": [
    "## Document Retreival Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87132b68-6623-4494-8afb-231904c22f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ID of SME for data labeling\n",
    "\n",
    "sme_id = 'sme_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3e4c5-25fd-45f5-be81-dc8a5cb837af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294931b7-a80c-4ada-9955-2910ba74b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57a577-f01e-4fa5-98ce-9227fcaeb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer, StorageContext\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c88b4d-6aac-4208-b4e3-fbdf6e6c0778",
   "metadata": {},
   "source": [
    "#### Recreating storage context object using same DB connections from ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f22e74-f4f8-4be7-83dc-27efe19fbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.redis import RedisVectorStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e3c80-dc51-42e0-a657-336f98f112b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "text_splitter = SentenceSplitter(chunk_size=3000)\n",
    "embed_model = OpenAI(model=\"text-embedding-3-small\")\n",
    "text_splitter = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ce53d-f5fa-492a-ad4d-dee5d4215341",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connecting to Redis DB through Python Redis Client (Refer to ingestion pipeline above for Redis Host-Port access)\n",
    "\n",
    "import redis\n",
    "redis_client = redis.Redis(\n",
    "  host='',\n",
    "  port=,\n",
    "  password='')\n",
    "\n",
    "## Setting up PGVector database\n",
    "\n",
    "from sqlalchemy import make_url\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "url = make_url(\"postgres://postgres.<username>:<password>@aws-0-us-west-1.pooler.supabase.com:5432/postgres\")\n",
    "db_name=\"postgres\"\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=url.database,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=sme_id,\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7209be-079e-48c0-a76e-30b169d75597",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-creating Storage context through Redis client (Refer to ingestion pipeline above for Redis Host-Port access):\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    index_store=RedisIndexStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b0b4-53d4-4f09-86df-e9ae019a0d6b",
   "metadata": {},
   "source": [
    "#### Creating steps to final response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d16ff0-a2ab-40eb-9fe6-51a6be717ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating prompt template\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))\n",
    "\n",
    "new_summary_tmpl_str = (\n",
    "    \"Context information is below:\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge,\"\n",
    "    \"answer the query in the style of a McKinsey, Bain or BCG consultant who specializes in digital transformation strategies.\"\n",
    "    \"Your goal is to help business users succeed in their digital transformation journeys.\"\n",
    "    \"Do not use any context outside of these documents.\"\n",
    "    \"If a question is outside of your area of expertise, politely refuse to answer and suggest alternative topics of discussion from the context provided.\"\n",
    "    \"You should maintain a friendly yet professional tone.\"\n",
    "    \"Use detailed bullet points whenever relevant.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "new_summary_tmpl = PromptTemplate(new_summary_tmpl_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1d4c6-58a2-4a95-bf37-072c0eebd6c7",
   "metadata": {},
   "source": [
    "#### Loading document summary index using storage context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51d093-5649-4237-b37c-bf2edbfd0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexEmbeddingRetriever,\n",
    ")\n",
    "\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "doc_summary_index = load_index_from_storage(\n",
    "    storage_context=storage_context\n",
    ")\n",
    "\n",
    "# Configuring response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(streaming=True, response_mode=\"tree_summarize\")\n",
    "\n",
    "## Creating Retreiver object\n",
    "retriever = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    doc_summary_index,\n",
    "    choice_batch_size=10,\n",
    "    choice_top_k=5\n",
    ")\n",
    "\n",
    "# Assembling query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "## Checking default query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)\n",
    "\n",
    "## Modifying query prompt\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": new_summary_tmpl}\n",
    ")\n",
    "\n",
    "## Checking modified query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc5c45-a2f5-4e0b-b6e0-726f8702d3f3",
   "metadata": {},
   "source": [
    "### Implementing embeddings Retirever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d6f9a-7d54-492f-a02e-6604ea7e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# query\n",
    "response = query_engine.query(\"What are the most important considerations when implementing a digital twin?\")\n",
    "response.print_response_stream()\n",
    "\n",
    "## Use streaming response in block:\n",
    "'''for text in streaming_response.response_gen:\n",
    "    # do something with text as they arrive.\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8f57b-d88f-4258-bdba-a6627ea0cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fin ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bde9b-b333-4961-a432-c37859d5fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restart kernel to test Pipeline below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2cc92-c8f6-4990-9b3e-d46dc9cc6305",
   "metadata": {},
   "source": [
    "## SME Data Insertion-Deletion (updation) pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea67cc0-5431-4fe7-9732-35b5ddc3b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ID of SME for data labeling\n",
    "\n",
    "sme_id = 'sme_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a8614e-23e8-4742-a66a-c0323547da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f2ffabe-6ddd-42fb-a666-d0574238bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719f2df2-3307-4f08-a473-26773a7ca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer, StorageContext\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97b598-f215-4f18-96fb-ee956b6d6651",
   "metadata": {},
   "source": [
    "#### Parsing new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866c8a54-84cc-4be9-b5da-b0894ece3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./ritika_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744e7c71-bfdb-41f5-a1cf-18b4d81e4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [#\"Decarbonizing-the-Built-World-A-Call-to-Action-2023-03-07\",\n",
    "             #\"Digital-Twin-Capabilities-Periodic-Table-User-Guide\",\n",
    "             #\"Digital-Twin-System-Interoperability-Framework-12072021\",\n",
    "             #\"DTC-Reality-Capture-Industry-User-Guide-for-Tenant-Improvement-Projects-2023-06-07\",\n",
    "             #\"Infrastructure-Digital-Twin-Maturity-Model\"]\n",
    "             \"Platform-Stack-Architectural-Framework\",\n",
    "             \"Reality-Capture-A-Digital-Twin-Foundation\",\n",
    "             \"SMM-Digital-Twin-Profile-2022-06-20\",\n",
    "             \"User-Guide-1-Why-and-What-2023-07-18\",\n",
    "             \"User-Guide-2-Identifying-and-Aligning\",\n",
    "             \"User-Guide-3_A-Whole_Systems_Approach\"]\n",
    "\n",
    "new_docs = []\n",
    "\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"{data_root}/{filename}.pdf\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\",\"\")\n",
    "    new_docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ade2f-61de-4c8c-bb35-4ca82d90664a",
   "metadata": {},
   "source": [
    "#### Redis-Based Ingestion Pipeline for Doc store and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72968092-a7e7-43c9-a612-3eec4775adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.redis import RedisVectorStore\n",
    "from llama_index.storage.index_store.redis import RedisIndexStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e0567b6-4256-4365-93cb-2d7d3373a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "text_splitter = SentenceSplitter(chunk_size=3000)\n",
    "embed_model = OpenAI(model=\"text-embedding-3-small\")\n",
    "text_splitter = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e6463-07c7-4cb2-ae02-302a64ea00e8",
   "metadata": {},
   "source": [
    "#### Setting up document store, index store and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad40053-8ed1-4771-8fa5-404075f8c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up connection to Redis two ways:\n",
    "\n",
    "## Through Python Redis client:\n",
    "\n",
    "import redis\n",
    "redis_client = redis.Redis(\n",
    "  host='',\n",
    "  port=,\n",
    "  password='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6fc5531-b311-47e9-b237-6a584c8dcb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining PGVector database:\n",
    "\n",
    "from sqlalchemy import make_url\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "url = make_url(\"postgres://postgres.<username>:<password>@aws-0-us-west-1.pooler.supabase.com:5432/postgres\")\n",
    "db_name=\"postgres\"\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=url.database,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=sme_id,\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbc5d5-4d4d-4ff4-8343-033b86771c55",
   "metadata": {},
   "source": [
    "#### Loading Index from storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12831a82-53b6-47e9-88bc-0dff4916f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-creating Storage context through Redis client (Refer to ingestion pipeline above for Redis Host-Port access):\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=RedisDocumentStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    index_store=RedisIndexStore.from_redis_client(\n",
    "        redis_client=redis_client, namespace=sme_id\n",
    "    ),\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode = \"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acf2504a-8ad7-4c12-89ad-997e14f2b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "doc_summary_index = load_index_from_storage(\n",
    "    storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ae65e0-f646-485a-ad44-0670db13d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: Platform-Stack-Architectural-Framework\n",
      "current doc id: 3995e90f-10a5-4ab0-bd41-1c493ea06d48\n",
      "current doc id: 2a04a3ad-e4f1-4372-9462-ac718d1b1dd6\n",
      "current doc id: 29f72723-a6ea-48d9-a9ea-d3cbd57244d8\n",
      "current doc id: c3dda7fb-ab2b-440d-b341-4db9adb08bcf\n",
      "current doc id: b577acb1-0bb4-4ff2-958a-33195f6bd4c2\n",
      "current doc id: 830e0fa8-d46c-43e2-ac7c-85934ee21ea4\n",
      "current doc id: 7b55aec5-630d-464e-b945-af640049ba9b\n",
      "current doc id: 9fed0941-8cee-4202-8b64-2d6ba83c678f\n",
      "current doc id: ad698a3d-e128-474a-ab4c-a1a3c6643a34\n",
      "current doc id: 79b035e5-7721-46cc-a25d-ff2525d2110d\n",
      "current doc id: 38e51a78-df7d-4ef3-ab95-fdb3cfed5a7a\n",
      "current doc id: f6921b4f-d892-40c9-8566-1d176113b08d\n",
      "current doc id: ca2563e3-ad96-4ae9-90e8-031c76915d25\n",
      "current doc id: 42315617-a4a5-4d96-bb08-8be63c21b798\n",
      "current doc id: 5ccc2b82-c456-471f-83da-be49726ee223\n",
      "current doc id: fe8522a1-825b-4421-9de8-92accd7a3b29\n",
      "current doc id: 8fc521d3-e508-4f36-b957-9b37b103f665\n",
      "current doc id: 4f886d51-d39f-4e0f-a305-86b7ff969445\n",
      "current doc id: 9cae4180-9291-487b-9937-5aa80f20e12b\n",
      "current doc id: 88e0500e-ca10-4028-a72a-b8c59e93a189\n",
      "current doc id: 4d0b4686-4ee2-4899-b1a7-fd53109a3136\n",
      "current doc id: 022b0660-e014-43b4-9425-a41b67725d2a\n",
      "current doc id: 1e9882ea-4a7f-433b-ad43-8e54523f4afb\n",
      "current doc id: fe71d771-0776-43be-8ba6-672ff82f8cc9\n",
      "current doc id: a4fa23d8-f31e-4b83-8222-9ed8c2da6e42\n",
      "current doc id: 427753ee-c935-4fe0-9b76-361e220200e0\n",
      "current doc id: 853dd84c-8e59-4c3e-9990-3dd58a410d3c\n",
      "current doc id: ff2b9c64-414f-42e0-b6c1-4c71984bed7d\n",
      "current doc id: 6ee964b3-795a-4ad3-8cbf-7a7d619cd883\n",
      "current doc id: f24c6189-6025-4e12-a14a-c77604ddb5a7\n",
      "current doc id: bd7736eb-9025-49b5-b866-a620f00e5743\n",
      "current doc id: 44ce38c2-57c3-4a80-b01c-083dd70981de\n",
      "current doc id: de3fca2a-544b-458e-b0c0-945fe4b556f2\n",
      "current doc id: 7ed6eae8-265a-4af5-9019-b7b0bece8d85\n",
      "current doc id: f4559958-c524-4495-8937-e72ced61a4f9\n",
      "current doc id: 92b094be-7d84-4356-a91a-860d21cf4959\n",
      "current doc id: dfa800f4-4e3d-4edc-b2fb-7668439281f1\n",
      "current doc id: d464d6f8-1691-4121-b9aa-eb81c4a2e478\n",
      "current doc id: 71d25dd8-5fa4-4b0c-80e2-da13f2264eae\n",
      "current doc id: 4df44912-1a83-4dc3-b9f7-a954bc2a3523\n",
      "current doc id: f911dc44-8e8d-4512-ba82-600e94b6b507\n",
      "current doc id: d6fb1dd2-12f6-4967-8c12-b6167ae93642\n",
      "current doc id: 49f8dcd0-cc8f-4956-a2a7-ee9a477b2dba\n",
      "current doc id: beaba269-4e65-442a-83e9-fe933b55d53e\n",
      "current doc id: cd39511b-88f7-4542-b46c-8d59adb1d72d\n",
      "current doc id: 753583ae-8832-4e1a-8e37-4dec33b4fe4a\n",
      "current doc id: f7d5d7fd-da2d-4717-a9b7-b8400375c81b\n",
      "current doc id: bbdfa39a-88e9-44bd-936c-5b83c9e420d7\n",
      "current doc id: Reality-Capture-A-Digital-Twin-Foundation\n",
      "current doc id: 8bccf1ef-cc7f-4275-8da2-f638c032e733\n",
      "current doc id: 5497a9db-c6d8-4708-a01f-507f57059ae6\n",
      "current doc id: eb2c7d28-3da5-4b84-b92e-7ffe73ce9628\n",
      "current doc id: de738ea9-0de1-4f23-9666-63703c34d8f9\n",
      "current doc id: 13253561-bfec-4a3d-aced-8505b23783fc\n",
      "current doc id: 3cc1c5c5-1176-4b92-b856-234ad0a9f7e5\n",
      "current doc id: bd41ec26-9d72-48bc-adce-cac49574eabe\n",
      "current doc id: 83f3780b-5928-4c8a-9055-ae49e98733fd\n",
      "current doc id: acbb0f5e-74c3-4b19-90b2-c8d85f65d177\n",
      "current doc id: 3ef5d26b-4ae0-4000-bd2d-8c8fb7214346\n",
      "current doc id: e6a4d882-9af5-41c4-98e2-54d82fefab9e\n",
      "current doc id: 8e2ca38e-2203-4d48-bc0f-fb42e0df355e\n",
      "current doc id: SMM-Digital-Twin-Profile-2022-06-20\n",
      "current doc id: 1755be2d-c029-44b3-a05b-33e4206929e1\n",
      "current doc id: 83eff4e1-a698-4fc0-b5a6-f671f88d8a40\n",
      "current doc id: 3ffbb01c-5ab4-47d8-98fb-a227ca4e44f7\n",
      "current doc id: 5178b674-d4b1-4181-b7a7-46a9942c601f\n",
      "current doc id: 4b3860b7-e51c-42ba-aaed-3d88116d719e\n",
      "current doc id: 090c19f9-d660-458f-bb38-266ffd571cc8\n",
      "current doc id: 7e92f85b-ad9b-478a-a6a2-80511b4b0de2\n",
      "current doc id: c62d4895-4a0a-4e2f-aec0-8033295cdf6b\n",
      "current doc id: 714bc98e-816d-4108-84f3-4a3e520d8240\n",
      "current doc id: 7837ef3b-1bcd-4e9c-ba0f-af3fd420f907\n",
      "current doc id: 3db53362-06f1-46df-9a75-a79abfd902be\n",
      "current doc id: 4931a8e2-e2f5-4a57-be3e-4aa79eeea11e\n",
      "current doc id: ad523fbf-67e6-480e-b317-0623bdd12bf9\n",
      "current doc id: b481ca3f-0044-4bdf-bb5b-39838b6a6692\n",
      "current doc id: 660b9c8e-4d20-463b-b6ab-37a53d7a2ecb\n",
      "current doc id: 4c6db7c3-ab8a-4794-9e73-10d0f0ae5c73\n",
      "current doc id: 2e77598d-81e0-48c4-99c6-6e3907967ef6\n",
      "current doc id: 026f1521-4e7d-49e0-b0b9-c9a17ca18a5b\n",
      "current doc id: 3aee5c87-046d-4379-9d4a-78bb51398ebf\n",
      "current doc id: 7aa857cd-842f-4f9f-a556-c4d2ade4144c\n",
      "current doc id: 42c973ad-7bf2-41a7-8606-18d8039ba410\n",
      "current doc id: 996679b3-c603-4451-a6c9-19033369218c\n",
      "current doc id: c91a76b8-6444-4748-b601-199d988622f6\n",
      "current doc id: 1ff1743f-9cbd-4d09-8c79-262a21429762\n",
      "current doc id: 0b50e0f2-ead8-4294-8f9c-7a43b84fde30\n",
      "current doc id: 972bc008-5d2a-486c-8fd9-dae5fd3b1db7\n",
      "current doc id: e977c521-ffb7-40a9-9e45-8883bec6ae4c\n",
      "current doc id: 1e324a56-e624-4c62-896e-c6ce64f399e6\n",
      "current doc id: 9bdd8417-0f0e-4d02-9b43-baf71cd0aa7a\n",
      "current doc id: 0364aeed-342f-4f6f-bdd4-030b8cdf1751\n",
      "current doc id: dc5781bb-a7e0-43e3-8d15-5fcde66686e5\n",
      "current doc id: 864054e1-863b-466e-b257-b4cbca2979e2\n",
      "current doc id: 594a234f-f8ac-4eac-9407-800e38f5bd25\n",
      "current doc id: c48f0078-b82a-47e1-9295-758ce9097788\n",
      "current doc id: a89b96a4-1395-48d4-bed5-6dc5321280b4\n",
      "current doc id: cf07f4eb-fba1-4b25-a38f-13103cfdde98\n",
      "current doc id: e5c740e0-7d41-4877-bec5-57e902c89802\n",
      "current doc id: 3d29e5c4-9777-4186-a859-25049f6dc033\n",
      "current doc id: d5447048-b1ff-4560-9db6-c20aa6736893\n",
      "current doc id: 72aff10c-0cd0-46e4-a3ca-0519e8eb298a\n",
      "current doc id: bc5605ec-c476-4bda-8b67-85d7bb4eba38\n",
      "current doc id: 504a1d50-9db2-4d51-b104-f39b5efa7c60\n",
      "current doc id: cf707832-10f6-432d-a68b-72ff592d8461\n",
      "current doc id: dc67c8f7-d781-4c6b-a74e-950e4d6ef530\n",
      "current doc id: ea81204e-7225-4a1d-8cad-db64158daa11\n",
      "current doc id: 3198b600-fe23-4ad9-89f0-0fb0cc233f0e\n",
      "current doc id: bb0a431c-763e-4928-b558-8fe523cdd81f\n",
      "current doc id: 35e6bff4-00bb-427a-9974-177ee4d96880\n",
      "current doc id: 9a178210-1dab-430d-8ab2-8e1efb2445a5\n",
      "current doc id: cffbf1b5-93c4-462e-9fa9-7414ac546a52\n",
      "current doc id: 8a484841-734f-43af-a5f5-e8c683b48e35\n",
      "current doc id: f8c8f61e-a098-4ffa-a8eb-ee2d4045c3e5\n",
      "current doc id: f72ae007-6d1a-4ecd-afe3-dae102bcb039\n",
      "current doc id: User-Guide-1-Why-and-What-2023-07-18\n",
      "current doc id: 5d1eadbc-4c63-4894-915c-c645f2ae4b23\n",
      "current doc id: 6191b068-3620-4760-9957-737cdc1292b7\n",
      "current doc id: 8967deb8-e273-49b7-9ab2-d13b003a77a1\n",
      "current doc id: 5fba61d7-fcea-4306-8312-a8fe4fdd9dff\n",
      "current doc id: 23361e20-df61-462e-8025-4bcd7c9545c6\n",
      "current doc id: 8c7f5144-8cca-41ee-b964-eafc8b5a8940\n",
      "current doc id: 18d09cf1-31d7-4523-9d68-34f507b8c555\n",
      "current doc id: 8ab99c3e-90b2-4206-a3bb-b945e8919dfb\n",
      "current doc id: 32f3b267-435c-46df-b2db-9e8b2ea394dd\n",
      "current doc id: d55d315d-7154-44a7-a780-84e4c8a3044d\n",
      "current doc id: 0350c7f5-56ad-4ad6-aea9-cddd7a0ae05d\n",
      "current doc id: db9d8fb3-e8a0-4c9f-b1ba-9a0a1df47bba\n",
      "current doc id: 121589a3-1891-4b17-bbde-1ef6b3fafaaf\n",
      "current doc id: 2124058d-d128-40f7-bedf-06c4b8519980\n",
      "current doc id: c8c6851b-648d-4f1a-bd36-01a46de2e39a\n",
      "current doc id: 46ec171d-1fc6-45df-9931-6e519eac6d8e\n",
      "current doc id: User-Guide-2-Identifying-and-Aligning\n",
      "current doc id: 74fdf3ec-205c-4eaa-b8b3-2a14c5bd7b4d\n",
      "current doc id: 2201cbb0-3dc7-4936-8b36-8573007a344e\n",
      "current doc id: e3e549e7-1776-4b60-9978-dedaebcaf44a\n",
      "current doc id: b6a33ae2-5b24-4ce0-8cc2-a13b7440702b\n",
      "current doc id: d2ee0c80-d6ca-4acd-b651-e23fa8277b38\n",
      "current doc id: 7f5aacf3-20ea-4c39-80c9-09772bf084c4\n",
      "current doc id: 693f6284-36fb-4ba5-95e8-34df0e9b2518\n",
      "current doc id: 147d6752-e12b-489a-b2c4-4f5fc05782ba\n",
      "current doc id: d8e90690-c1d1-4102-ac1f-9711fa99edf8\n",
      "current doc id: ddcadf64-ec92-4b9b-b898-7af1fe964876\n",
      "current doc id: 4af25e94-0154-45b3-a64a-e40102957b21\n",
      "current doc id: 0fc93d87-aba3-4b67-9e83-3d46362ce27b\n",
      "current doc id: User-Guide-3_A-Whole_Systems_Approach\n",
      "current doc id: 6608d82c-6b12-4d8a-9a04-5c5c4f8aa496\n",
      "current doc id: 0b998cf8-ad59-4b20-a344-5c4550a49158\n",
      "current doc id: 61ee29ab-b730-4ff1-a472-68ae05ca7035\n",
      "current doc id: e583dd9f-12e9-4421-9b2c-1c58fd9e0347\n",
      "current doc id: 682f438c-1976-4714-bae0-b8b403e75241\n",
      "current doc id: adb7a801-6f8f-4420-8657-8ed675cf18cf\n",
      "current doc id: 88869f45-afe4-4ef3-aebe-1986c6a0f310\n",
      "current doc id: 302e7010-8373-498d-9b32-fbd76e61690f\n",
      "current doc id: 5ad86d05-07b6-440c-8e97-c0506e343a1e\n",
      "current doc id: abc08e66-1d80-415e-9519-01046fead1fa\n",
      "current doc id: 8e5efbdb-3cfc-4db5-8bd9-888019cfe554\n",
      "current doc id: 537e9caf-03b5-4a5a-90a1-e65e78074d1b\n",
      "current doc id: a8cb43c9-331e-4dea-97e1-9c8bfbe4157b\n",
      "current doc id: bc41a8f8-529f-4515-b4b6-f9666dc22630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_summary_index.refresh(new_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1518b7-4fca-45e5-a757-65d15251caff",
   "metadata": {},
   "source": [
    "### Checking response after adding new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1e45bc-9de0-4a21-a8e3-de4aca5c60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating prompt template\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))\n",
    "\n",
    "new_summary_tmpl_str = (\n",
    "    \"Context information is below:\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge,\"\n",
    "    \"answer the query in the style of a McKinsey, Bain or BCG consultant who specializes in digital transformation strategies.\"\n",
    "    \"Your goal is to help business users succeed in their digital transformation journeys.\"\n",
    "    \"Do not use any context outside of these documents.\"\n",
    "    \"If a question is outside of your area of expertise, politely refuse to answer and suggest alternative topics of discussion from the context provided.\"\n",
    "    \"You should maintain a friendly yet professional tone.\"\n",
    "    \"Use detailed bullet points whenever relevant.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "new_summary_tmpl = PromptTemplate(new_summary_tmpl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d0a747f-f300-4098-8b44-99a0a78c10ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:summary_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:summary_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below:\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge,answer the query in the style of a McKinsey, Bain or BCG consultant who specializes in digital transformation strategies.Your goal is to help business users succeed in their digital transformation journeys.Do not use any context outside of these documents.If a question is outside of your area of expertise, politely refuse to answer and suggest alternative topics of discussion from the context provided.You should maintain a friendly yet professional tone.Use detailed bullet points whenever relevant.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexEmbeddingRetriever,\n",
    ")\n",
    "\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "#doc_summary_index = load_index_from_storage(\n",
    "#    storage_context=storage_context\n",
    "#)\n",
    "\n",
    "# Configuring response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(streaming=True, response_mode=\"tree_summarize\")\n",
    "\n",
    "## Creating Retreiver object\n",
    "retriever = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    doc_summary_index,\n",
    "    choice_batch_size=10,\n",
    "    choice_top_k=5\n",
    ")\n",
    "\n",
    "# Assembling query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "## Checking default query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)\n",
    "\n",
    "## Modifying query prompt\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": new_summary_tmpl}\n",
    ")\n",
    "\n",
    "## Checking modified query prompt:\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13781788-ee0c-4f99-8207-264492c26baa",
   "metadata": {},
   "source": [
    "### Implementing embeddings Retirever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c59d9c6-57b1-4d37-881c-5d62c902d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the question about the capital of South Sudan is outside the scope of the context provided, which focuses on decarbonization across the building lifecycle. \n",
      "\n",
      "However, I can provide insights and recommendations related to sustainability assessment methods and certification tools for building projects. Would you like to discuss how to choose the best sustainability assessment method for your project or how to track key performance metrics across the design lifecycle?--- 1.9458940029144287 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# query\n",
    "response = query_engine.query(\"What is the capital of south sudan?\")\n",
    "response.print_response_stream()\n",
    "\n",
    "## Use streaming response in block:\n",
    "'''for text in streaming_response.response_gen:\n",
    "    # do something with text as they arrive.\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134a7c1-1a26-46be-882d-ddf710d1c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
